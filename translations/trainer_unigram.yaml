title:
  original: Unigram tokenizer trainer
  translation: Processus d'entraînement Unigram
description:
  original: |
    Unigram tokenizer trainer

    Unigram tokenizer trainer
  translation: |
    Processus d'entraînement Unigram
seealso:
  original: "Other trainer: \n\\code{\\link{tok_trainer}},\n\\code{\\link{trainer_bpe}},\n\\code{\\link{trainer_wordpiece}}\n"
  translation: "Autres processus d'entraînement : \n\\code{\\link{tok_trainer}},\n\\code{\\link{trainer_bpe}},\n\\code{\\link{trainer_wordpiece}}\n"
section{Super class}:
  original: |
    \code{\link[tok:tok_trainer]{tok::tok_trainer}} -> \code{tok_trainer_unigram}
  translation: ~
section{Methods}:
  original: |
    \subsection{Public methods}{
    \itemize{
    \item \href{#method-tok_trainer_unigram-new}{\code{trainer_unigram$new()}}
    \item \href{#method-tok_trainer_unigram-clone}{\code{trainer_unigram$clone()}}
    }
    }
    \if{html}{\out{<hr>}}
    \if{html}{\out{<a id="method-tok_trainer_unigram-new"></a>}}
    \if{latex}{\out{\\hypertarget{method-tok_trainer_unigram-new}{}}}
    \subsection{Method \code{new()}}{
    Constructor for the Unigram tokenizer
    \subsection{Usage}{
    \if{html}{\out{<div class="r">}}\preformatted{trainer_unigram$new(
      vocab_size = 8000,
      show_progress = TRUE,
      special_tokens = NULL,
      shrinking_factor = 0.75,
      unk_token = NULL,
      max_piece_length = 16,
      n_sub_iterations = 2
    )}\if{html}{\out{</div>}}
    }

    \subsection{Arguments}{
    \if{html}{\out{<div class="arguments">}}
    \describe{
    \item{\code{vocab_size}}{The size of the final vocabulary, including all tokens and alphabet.}

    \item{\code{show_progress}}{Whether to show progress bars while training.}

    \item{\code{special_tokens}}{A list of special tokens the model should be aware of.}

    \item{\code{shrinking_factor}}{The shrinking factor used at each step of training
    to prune the vocabulary.}

    \item{\code{unk_token}}{The token used for out-of-vocabulary tokens.}

    \item{\code{max_piece_length}}{The maximum length of a given token.}

    \item{\code{n_sub_iterations}}{The number of iterations of the EM algorithm to perform
    before pruning the vocabulary.}

    \item{\code{initial_alphabet}}{A list of characters to include in the initial alphabet,
    even if not seen in the training dataset. If the strings contain more than
    one character, only the first one is kept.}
    }
    \if{html}{\out{</div>}}
    }
    }
    \if{html}{\out{<hr>}}
    \if{html}{\out{<a id="method-tok_trainer_unigram-clone"></a>}}
    \if{latex}{\out{\\hypertarget{method-tok_trainer_unigram-clone}{}}}
    \subsection{Method \code{clone()}}{
    The objects of this class are cloneable with this method.
    \subsection{Usage}{
    \if{html}{\out{<div class="r">}}\preformatted{trainer_unigram$clone(deep = FALSE)}\if{html}{\out{</div>}}
    }

    \subsection{Arguments}{
    \if{html}{\out{<div class="arguments">}}
    \describe{
    \item{\code{deep}}{Whether to make a deep clone.}
    }
    \if{html}{\out{</div>}}
    }
    }
  translation: |
    \subsection{Méthodes publiques}{
    \itemize{
    \item \href{#method-tok_trainer_unigram-new}{\code{formateur_unigram$new()}}
    \item \href{#method-tok_trainer_unigram-clone}{\code{formateur_unigram$clone()}}
    }
    }
    \if{html}{\out{<hr>}}
    \if{html}{\out{<a id="method-tok_trainer_unigram-new"></a>}}
    \if{latex}{\out{\\hypertarget{method-tok_trainer_unigram-new}{}}}
    \subsection{Méthode \code{new()}}{
    Constructeur pour le jeton unigramme
    \subsection{Usage}{
    \if{html}{\out{<div class="r">}}\preformatted{trainer_unigram$new(
      vocab_size = 8000,
      show_progress = TRUE,
      special_tokens = NULL,
      shrinking_factor = 0.75,
      unk_token = NULL,
      max_piece_length = 16,
      n_sub_iterations = 2
    )}\if{html}{\out{</div>}}
    }

    \subsection{Arguments}{
    \if{html}{\out{<div class="arguments">}}
    \describe{
    \item{\code{vocab_size}}{La taille du vocabulaire final, y compris tous les tokens et alphabet.}
  
    \item{\code{show_progress}}{Si vous devez montrer des barres de progression pendant l'entraînement.}
  
    \item{\code{tokens_speciaux}}{Une liste de tokens spéciaux que le modèle doit inclure.}
  
    \item{\code{facteur_de_réduction}}{Le facteur de réduction utilisé à chaque étape de l'entraînement pour réduire le vocabulaire.}
  
    \item{\code{token_unk}}{Le token utilisé pour les tokens hors vocabulaire.}
  
    \item{\code{longueur_maximale_piece}}{La longueur maximale d'un token donné.}
  
    \item{\code{nombre_iterations_sous}}{Le nombre d'itérations de l'algorithme EM à effectuer avant de réduire le vocabulaire.}
  
    \item{\code{alphabet_initial}}{Une liste de caractères à inclure dans l'alphabet initial, même s'ils n'ont pas été vus dans l'ensemble de données d'entraînement. Si les chaînes 
    contiennent plus d'un caractère, seul le premier est conservé.}
    }
    \if{html}{\out{</div>}}
    }
    }
    \if{html}{\out{<hr>}}
    \if{html}{\out{<a id="method-tok_trainer_unigram-clone"></a>}}
    \if{latex}{\out{\\hypertarget{method-tok_trainer_unigram-clone}{}}}
    \subsection{Méthode \code{clone()}}{
    Les objets de cette classe sont clonables avec cette méthode.
    \subsection{Usage}{
    \if{html}{\out{<div class="r">}}\preformatted{trainer_unigram$clone(deep = FALSE)}\if{html}{\out{</div>}}
    }
  
    \subsection{Arguments}{
    \if{html}{\out{<div class="arguments">}}
    \describe{
    \item{\code{deep}}{Si vous devez faire une copie profonde.}
    }
    \if{html}{\out{</div>}}
    }
    }

untranslatable:
- alias
- name
- keyword
- concept
- usage
